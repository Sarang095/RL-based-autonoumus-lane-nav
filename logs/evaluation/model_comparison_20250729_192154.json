{
  "imitation_learning": {
    "model_type": "imitation",
    "timestamp": "2025-07-29T19:20:38.744768",
    "scenarios": {
      "highway": {
        "episode_rewards": [
          141.21477855599815,
          132.56359206796614,
          125.97698258525418,
          126.07238868815146,
          110.57648317329921,
          107.69803687136893,
          134.62881321360703,
          119.9071547485628,
          121.73308290148947,
          115.1327840780977,
          121.28554999443371,
          135.42773978448167,
          138.683424963156,
          138.61980991911133,
          106.777493773908,
          132.35829886941946,
          134.3216011241172,
          128.60042304095575,
          137.5292372887518,
          124.78441118799282
        ],
        "episode_lengths": [
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200
        ],
        "avg_reward": 126.69460434150612,
        "std_reward": 10.337401691804242,
        "avg_length": 200.0,
        "std_length": 0.0,
        "success_rate": 1.0,
        "collision_rate": 0.0,
        "num_episodes": 20
      }
    },
    "overall_stats": {
      "avg_reward": 126.69460434150612,
      "std_reward": 10.337401691804242,
      "avg_length": 200.0,
      "std_length": 0.0,
      "overall_success_rate": 1.0,
      "total_episodes": 20
    }
  },
  "ppo": {
    "model_type": "ppo",
    "timestamp": "2025-07-29T19:21:14.494635",
    "scenarios": {
      "highway": {
        "episode_rewards": [
          132.85690653315743,
          141.0746650819755,
          152.3296433457726,
          152.32964041922276,
          141.07466454004418,
          146.33850411935575,
          141.07466437771896,
          146.33850191894823,
          152.3296439039921,
          132.85690653122157,
          132.8569067042776,
          152.32964329825614,
          132.8569066194293,
          152.32964059034757,
          132.8569064654965,
          152.3296443111706,
          141.07466469347585,
          141.0746655431037,
          152.3296429826263,
          141.07466388047453
        ],
        "episode_lengths": [
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200,
          200
        ],
        "avg_reward": 143.48585129300335,
        "std_reward": 7.627316116108415,
        "avg_length": 200.0,
        "std_length": 0.0,
        "success_rate": 1.0,
        "collision_rate": 0.0,
        "num_episodes": 20
      }
    },
    "overall_stats": {
      "avg_reward": 143.48585129300335,
      "std_reward": 7.627316116108415,
      "avg_length": 200.0,
      "std_length": 0.0,
      "overall_success_rate": 1.0,
      "total_episodes": 20
    }
  },
  "comparison_summary": {
    "reward_improvement": 16.79124695149723,
    "success_rate_improvement": 0.0,
    "length_difference": 0.0,
    "better_model": "PPO",
    "reward_winner": "PPO",
    "success_winner": "IL"
  }
}